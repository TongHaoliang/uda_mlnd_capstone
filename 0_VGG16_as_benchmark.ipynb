{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2,time,glob,math\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "from tqdm import tqdm #进度条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设置一些基本参数\n",
    "train_dir = 'train'\n",
    "valid_dir = 'validation'\n",
    "test_dir = 'test2'\n",
    "nb_train_samples = sum([len(x) for _, _, x in os.walk(train_dir)])\n",
    "nb_valid_samples = sum([len(x) for _, _, x in os.walk(valid_dir)])\n",
    "nb_test_samples = sum([len(x) for _, _, x in os.walk(test_dir)])\n",
    "nb_categories = 10\n",
    "epochs = 5\n",
    "labels = [\" normal driving\",\"texting - right\",\"talking on the phone - right\",\"texting - left\",\n",
    "          \"talking on the phone - left\",\"operating the radio\",\n",
    "          \"drinking\",\" reaching behind\",\"hair and makeup\",\"talking to passenger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1828\n"
     ]
    }
   ],
   "source": [
    "print nb_valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set training parameters\n",
    "model_name = 'VGG16'\n",
    "fine_tune_layer = 0\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 1e-3\n",
    "augmentation = 'yes'\n",
    "valid_set = 'p056_p066'\n",
    "batch_size = 64\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:52<00:00, 33.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train data time: 352.64 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (20596, 224, 224, 3) Y_train shape: (20596, 10)\n",
      "Read validation images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read test data time: 12.28 seconds\n",
      "X_validation shape: (1828, 224, 224, 3) Y_validation shape: (1828, 10)\n"
     ]
    }
   ],
   "source": [
    "# 载入训练数据\n",
    "def load_train(img_width, img_height):\n",
    "    print('Read train images')\n",
    "    start_time = time.time()\n",
    "    X_train = np.zeros((nb_train_samples,img_width,img_height,3),dtype=np.uint8)\n",
    "    Y_train = []\n",
    "    X_train_id = []\n",
    "    count = 0\n",
    "    mean_pixel = [103.939, 116.779, 123.68]\n",
    "    for i in tqdm(range(nb_categories)):\n",
    "        path = os.path.join(train_dir,'c'+str(i), '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = load_img(fl,False,target_size=(img_width,img_height))\n",
    "            img = img_to_array(img)\n",
    "            X_train[count][:] = img\n",
    "            count = count + 1\n",
    "            X_train_id.append(flbase)\n",
    "            Y_train.append(i)\n",
    "    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    X_train = X_train.astype('float32')\n",
    "    for c in range(3):\n",
    "        X_train[:, :, :, c] = X_train[:, :, :, c] - mean_pixel[c]\n",
    "    Y_train = np.array(Y_train,dtype=np.uint8)\n",
    "    Y_train = np_utils.to_categorical(Y_train, nb_categories) \n",
    "    print \"X_train shape:\", X_train.shape, \"Y_train shape:\",Y_train.shape\n",
    "    return X_train, X_train_id,Y_train\n",
    "X_train, X_train_id,Y_train = load_train(img_width,img_height)\n",
    "\n",
    "# 载入验证数据\n",
    "def load_validation(img_width, img_height, color_type=3):\n",
    "    print('Read validation images')\n",
    "    start_time = time.time()\n",
    "    X_validation = np.zeros((nb_valid_samples,img_width,img_height,3),dtype=np.uint8)\n",
    "    Y_validation = []\n",
    "    X_validation_id = []\n",
    "    count = 0\n",
    "    mean_pixel = [103.939, 116.779, 123.68]\n",
    "    for i in tqdm(range(nb_categories)):\n",
    "        path = os.path.join('validation','c'+str(i), '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for fl in files:\n",
    "            flbase = os.path.basename(fl)\n",
    "            img = load_img(fl,False,target_size=(img_width,img_height))\n",
    "            img = img_to_array(img)\n",
    "            X_validation[count][:] = img\n",
    "            count = count + 1\n",
    "            X_validation_id.append(flbase)\n",
    "            Y_validation.append(i)\n",
    "    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n",
    "    X_validation= X_validation.astype('float32')\n",
    "    for c in range(3):\n",
    "        X_train[:, :, :, c] = X_train[:, :, :, c] - mean_pixel[c]\n",
    "    Y_validation = np.array(Y_validation,dtype=np.uint8)\n",
    "    Y_validation = np_utils.to_categorical(Y_validation, nb_categories) \n",
    "    print \"X_validation shape:\", X_validation.shape, \"Y_validation shape:\",Y_validation.shape\n",
    "    return X_validation, X_validation_id,Y_validation\n",
    "X_validation, X_validation_id,Y_validation = load_validation(img_width,img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datagen fit time:5.95 seconds\n"
     ]
    }
   ],
   "source": [
    "#对图像进行预处理\n",
    "datagen = ImageDataGenerator(\n",
    "    #rescale=1./255,   only need to substract mean, should not divide by 255\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1)\n",
    "start_time = time.time()\n",
    "datagen.fit(X_train)\n",
    "print 'datagen fit time:{} seconds'.format(round(time.time() - start_time, 2))\n",
    "train_generator = datagen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "\n",
    "#validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator()\n",
    "validation_datagen.fit(X_validation)\n",
    "validation_generator = validation_datagen.flow(X_validation, Y_validation, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build network on top of VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width,img_height, 3)) \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x) \n",
    "x = Dense(nb_categories, activation='softmax')(x) #10categories in our case\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x) #add top layers to VGG16\n",
    "#set VGG16 layers to non-trainable, train top layers for a few epoches first\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "try:\n",
    "    model.load_weights('model/VGG16toptrained.h5')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练top\n",
    "model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_train_samples//batch_size,epochs=1,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=nb_valid_samples//batch_size)\n",
    "model.save_weights('models/VGG16toptrained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Fine tune 模型\n",
    "#lock VGG16 layers, execpt the last CNN block. \n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#recomplie the optimizer, use SGD at a low learning rate \n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True), \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#训练fine-tune模型\n",
    "result = model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_train_samples//batch_size,epochs=10,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=nb_valid_samples//batch_size)\n",
    "model.save_weights('models/VGG16fine_tuned.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
