{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2,time,glob,math\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "from tqdm import tqdm #进度条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设置一些基本参数\n",
    "train_dir = 'train'\n",
    "valid_dir = 'validation'\n",
    "test_dir = 'test2'\n",
    "nb_train_samples = sum([len(x) for _, _, x in os.walk(train_dir)])\n",
    "nb_valid_samples = sum([len(x) for _, _, x in os.walk(valid_dir)])\n",
    "nb_test_samples = sum([len(x) for _, _, x in os.walk(test_dir)])\n",
    "nb_categories = 10\n",
    "epochs = 5\n",
    "labels = [\" normal driving\",\"texting - right\",\"talking on the phone - right\",\"texting - left\",\n",
    "          \"talking on the phone - left\",\"operating the radio\",\n",
    "          \"drinking\",\" reaching behind\",\"hair and makeup\",\"talking to passenger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set training parameters\n",
    "model_name = 'ResNet50'\n",
    "fine_tune_layer = 0\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 1e-6\n",
    "augmentation = 'yes'\n",
    "valid_set = 'p014_p039'\n",
    "batch_size = 16\n",
    "img_width, img_height = 400, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20897 images belonging to 10 classes.\n",
      "Found 1527 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 利用Keras的ImageDataGenerator对图片进行预处理\n",
    "def preprocess_input(x):\n",
    "    x = x[..., ::-1]\n",
    "    x = x - [103.939, 116.779, 123.68]\n",
    "    return x\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=15) \n",
    "#考虑到体型、姿势略有不同，设置少许的旋转、放大缩小和平移。不做翻转） \n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "#验证集和测试集无须进行上述处理，保留原样\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  \n",
    "        target_size=(img_width,img_height),  \n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        valid_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total layer count:  175 | fine tune layer:  0\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(img_width, img_height, 3))\n",
    "base_model = ResNet50(input_tensor=inputs, weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs, x)\n",
    "\n",
    "print 'total layer count: ', len(base_model.layers),\n",
    "print '| fine tune layer: ', fine_tune_layer\n",
    "\n",
    "for i in range(fine_tune_layer):\n",
    "    model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 211/1307 [===>..........................] - ETA: 1509s - loss: 0.0167 - acc: 0.9947"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ec32d836c199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                    validation_steps=nb_valid_samples//batch_size+1)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/ResNet50_400_300_p014_p039_l0.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mlnd-dl/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result = model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_train_samples//batch_size+1,\n",
    "                   epochs=1,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=nb_valid_samples//batch_size+1)\n",
    "model.save_weights('models/ResNet50_400_300_p014_p039_l0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  | layer|  opt  |  l-rate |  aug  |    driver   |batch | epo |  t_acc  |  t_loss |  v_acc  | v_loss \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "ResNet50  |  0  |  Adam  |  0.0001  |  yes  |  p014_p039  |  16  |  0  |  0.903  |  0.312  |  0.912  |  0.260\n"
     ]
    }
   ],
   "source": [
    "#write results, use'a' to countinue writing\n",
    "import csv\n",
    "print 'model  | layer|  opt  |  l-rate |  aug  |    driver   |batch | epo |  t_acc  |  t_loss |  v_acc  | v_loss '\n",
    "print '----------------------------------------------------------------------------------------------------------'\n",
    "with open(\"result201102.csv\",\"a\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(len(result.epoch)):\n",
    "        writer.writerow([model_name, fine_tune_layer, optimizer, learning_rate, augmentation, \n",
    "                         valid_set, batch_size, result.epoch[i], '%.3f' % result.history['acc'][i],  \n",
    "                         '%.3f' % result.history['loss'][i], '%.3f' % result.history['val_acc'][i],\n",
    "                         '%.3f' % result.history['val_loss'][i]])\n",
    "        print model_name,' | ', fine_tune_layer,' | ', optimizer, ' | ',learning_rate,' | ', augmentation,\n",
    "        print ' | ',valid_set, ' | ', batch_size, ' | ', result.epoch[i], ' | ', \n",
    "        print '%.3f' % result.history['acc'][i],' | ','%.3f' % result.history['loss'][i], ' | ',\n",
    "        print '%.3f' % result.history['val_acc'][i],' | ','%.3f' % result.history['val_loss'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception  |  0  |  Adam  |  0.0001  |  yes  |  p045_p047  |  16  |  0  |  0.925  |  0.251  |  0.887  |  0.428  | \n",
      "Xception  |  0  |  Adam  |  1e-05  |  yes  |  p045_p047  |  16  |  0  |  0.993  |  0.028  |  0.904  |  0.453  | \n",
      "Xception  |  126  |  Adam  |  1e-05  |  yes  |  p045_p047  |  64  |  0  |  0.623  |  1.294  |  0.743  |  0.751  | \n",
      "Xception  |  126  |  Adam  |  1e-05  |  yes  |  p045_p047  |  64  |  0  |  0.874  |  0.544  |  0.748  |  0.727  | \n",
      "Xception  |  66  |  Adam  |  0.0001  |  yes  |  p045_p047  |  64  |  0  |  0.940  |  0.241  |  0.838  |  0.445  | \n",
      "Xception  |  66  |  Adam  |  1e-06  |  yes  |  p045_p047  |  64  |  0  |  0.991  |  0.037  |  0.883  |  0.365  | \n",
      "Xception  |  66  |  Adam  |  1e-06  |  yes  |  p045_p047  |  64  |  0  |  0.991  |  0.033  |  0.875  |  0.390  | \n",
      "ResNet50  |  0  |  Adam  |  0.0001  |  yes  |  p014_p039  |  16  |  0  |  0.903  |  0.312  |  0.912  |  0.260  | \n"
     ]
    }
   ],
   "source": [
    "#load csv and show results\n",
    "import csv\n",
    "with open('result201102.csv',\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #这里不需要readlines\n",
    "    for line in reader:\n",
    "        for i in range(len(line)):\n",
    "            print line[i],\" | \",\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4983/4983 [==============================] - 2369s  \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(test_generator,  steps=test_generator.samples//batch_size+1,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission saved\n"
     ]
    }
   ],
   "source": [
    "l = list()\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    name = fname[fname.rfind('/')+1:]\n",
    "    line = y_pred[i]\n",
    "    line = line.tolist()\n",
    "    line.insert(0,name)\n",
    "    l.append( line )\n",
    "\n",
    "l = np.array(l)\n",
    "data = {'img': l[:,0]}\n",
    "for i in range(10):\n",
    "    data[\"c%d\"%i] = l[:,i+1]\n",
    "df = pd.DataFrame(data, columns=['img'] + ['c%d'%i for i in range(10)])\n",
    "df = df.sort_values(by='img')\n",
    "df.to_csv('2_ResNet50_400_300_p014_p039_l0.csv', index=None, float_format='%.3f')\n",
    "print(\"submission saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_submission = pd.read_csv('2_ResNet50_400_300_p014_p039_l0.csv')\n",
    "clip_submission = pre_submission.drop('img',axis =1)\n",
    "clip_submission = clip_submission.clip(0.001,1)\n",
    "clip_submission.insert(0, 'img', pre_submission['img'])\n",
    "clip_submission.to_csv('clipped_2_ResNet50_400_300_p014_p039_l0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
