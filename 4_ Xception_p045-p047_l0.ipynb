{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2,time,glob,math\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "from tqdm import tqdm #进度条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设置一些基本参数\n",
    "train_dir = 'train'\n",
    "valid_dir = 'validation'\n",
    "test_dir = 'test2'\n",
    "nb_train_samples = sum([len(x) for _, _, x in os.walk(train_dir)])\n",
    "nb_valid_samples = sum([len(x) for _, _, x in os.walk(valid_dir)])\n",
    "nb_test_samples = sum([len(x) for _, _, x in os.walk(test_dir)])\n",
    "nb_categories = 10\n",
    "epochs = 5\n",
    "labels = [\" normal driving\",\"texting - right\",\"talking on the phone - right\",\"texting - left\",\n",
    "          \"talking on the phone - left\",\"operating the radio\",\n",
    "          \"drinking\",\" reaching behind\",\"hair and makeup\",\"talking to passenger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set training parameters\n",
    "model_name = 'Xception'\n",
    "fine_tune_layer = 0\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 1e-6\n",
    "augmentation = 'yes'\n",
    "valid_set = 'p045_p047'\n",
    "batch_size = 64\n",
    "img_width, img_height = 400, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20865 images belonging to 10 classes.\n",
      "Found 1559 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 利用Keras的ImageDataGenerator对图片进行预处理\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        rotation_range=15) \n",
    "#考虑到体型、姿势略有不同，设置少许的旋转、放大缩小和平移。不做翻转） \n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "#验证集和测试集无须进行上述处理，保留原样\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  \n",
    "        target_size=(img_width,img_height),  \n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        valid_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total layer count:  132 | fine tune from layer:  66\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(img_width, img_height, 3))\n",
    "base_model = Xception(input_tensor=inputs, weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs, x)\n",
    "\n",
    "print 'total layer count: ', len(base_model.layers),\n",
    "print '| fine tune from layer: ', fine_tune_layer\n",
    "\n",
    "for i in range(fine_tune_layer):\n",
    "    model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "327/327 [==============================] - 1223s - loss: 0.0382 - acc: 0.9885 - val_loss: 0.3895 - val_acc: 0.8749\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result = model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_train_samples//batch_size+1,\n",
    "                   epochs=1,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=nb_valid_samples//batch_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('models/Xception_p045_p047_l66.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  | layer|  opt  |  l-rate |  aug  |    driver   |batch | epo |  t_acc  |  t_loss |  v_acc  | v_loss \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "Xception  |  66  |  Adam  |  1e-06  |  yes  |  p045_p047  |  64  |  0  |  0.991  |  0.033  |  0.875  |  0.390\n"
     ]
    }
   ],
   "source": [
    "#write results, use'a' to countinue writing\n",
    "import csv\n",
    "print 'model  | layer|  opt  |  l-rate |  aug  |    driver   |batch | epo |  t_acc  |  t_loss |  v_acc  | v_loss '\n",
    "print '----------------------------------------------------------------------------------------------------------'\n",
    "with open(\"result201102.csv\",\"a\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(len(result.epoch)):\n",
    "        writer.writerow([model_name, fine_tune_layer, optimizer, learning_rate, augmentation, \n",
    "                         valid_set, batch_size, result.epoch[i], '%.3f' % result.history['acc'][i],  \n",
    "                         '%.3f' % result.history['loss'][i], '%.3f' % result.history['val_acc'][i],\n",
    "                         '%.3f' % result.history['val_loss'][i]])\n",
    "        print model_name,' | ', fine_tune_layer,' | ', optimizer, ' | ',learning_rate,' | ', augmentation,\n",
    "        print ' | ',valid_set, ' | ', batch_size, ' | ', result.epoch[i], ' | ', \n",
    "        print '%.3f' % result.history['acc'][i],' | ','%.3f' % result.history['loss'][i], ' | ',\n",
    "        print '%.3f' % result.history['val_acc'][i],' | ','%.3f' % result.history['val_loss'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception  |  0  |  Adam  |  0.0001  |  yes  |  p045_p047  |  16  |  0  |  0.925  |  0.251  |  0.887  |  0.428  | \n",
      "Xception  |  0  |  Adam  |  1e-05  |  yes  |  p045_p047  |  16  |  0  |  0.993  |  0.028  |  0.904  |  0.453  | \n",
      "Xception  |  126  |  Adam  |  1e-05  |  yes  |  p045_p047  |  64  |  0  |  0.623  |  1.294  |  0.743  |  0.751  | \n",
      "Xception  |  126  |  Adam  |  1e-05  |  yes  |  p045_p047  |  64  |  0  |  0.874  |  0.544  |  0.748  |  0.727  | \n",
      "Xception  |  66  |  Adam  |  0.0001  |  yes  |  p045_p047  |  64  |  0  |  0.940  |  0.241  |  0.838  |  0.445  | \n",
      "Xception  |  66  |  Adam  |  1e-06  |  yes  |  p045_p047  |  64  |  0  |  0.991  |  0.037  |  0.883  |  0.365  | \n",
      "Xception  |  66  |  Adam  |  1e-06  |  yes  |  p045_p047  |  64  |  0  |  0.991  |  0.033  |  0.875  |  0.390  | \n"
     ]
    }
   ],
   "source": [
    "#load csv and show results\n",
    "import csv\n",
    "with open('result201102.csv',\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #这里不需要readlines\n",
    "    for line in reader:\n",
    "        for i in range(len(line)):\n",
    "            print line[i],\" | \",\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246/1246 [==============================] - 3432s  \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(test_generator,  steps=test_generator.samples//batch_size+1,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission saved\n"
     ]
    }
   ],
   "source": [
    "l = list()\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    name = fname[fname.rfind('/')+1:]\n",
    "    line = y_pred[i]\n",
    "    line = line.tolist()\n",
    "    line.insert(0,name)\n",
    "    l.append( line )\n",
    "\n",
    "l = np.array(l)\n",
    "data = {'img': l[:,0]}\n",
    "for i in range(10):\n",
    "    data[\"c%d\"%i] = l[:,i+1]\n",
    "df = pd.DataFrame(data, columns=['img'] + ['c%d'%i for i in range(10)])\n",
    "df = df.sort_values(by='img')\n",
    "df.to_csv('4_Xception_p045_p047_l0.csv', index=None, float_format='%.3f')\n",
    "print(\"submission saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_submission = pd.read_csv('4_Xception_p045_p047_l0.csv')\n",
    "clip_submission = pre_submission.drop('img',axis =1)\n",
    "clip_submission = clip_submission.clip(0.001,1)\n",
    "clip_submission.insert(0, 'img', pre_submission['img'])\n",
    "clip_submission.to_csv('clipped_4_Xception_p045_p047_l0.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd-dl]",
   "language": "python",
   "name": "conda-env-mlnd-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
