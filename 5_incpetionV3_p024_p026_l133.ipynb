{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import *\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2,time,glob,math\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "from tqdm import tqdm #进度条"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#设置一些基本参数\n",
    "train_dir = 'train'\n",
    "valid_dir = 'validation'\n",
    "test_dir = 'test2'\n",
    "nb_train_samples = sum([len(x) for _, _, x in os.walk(train_dir)])\n",
    "nb_valid_samples = sum([len(x) for _, _, x in os.walk(valid_dir)])\n",
    "nb_test_samples = sum([len(x) for _, _, x in os.walk(test_dir)])\n",
    "nb_categories = 10\n",
    "epochs = 5\n",
    "labels = [\" normal driving\",\"texting - right\",\"talking on the phone - right\",\"texting - left\",\n",
    "          \"talking on the phone - left\",\"operating the radio\",\n",
    "          \"drinking\",\" reaching behind\",\"hair and makeup\",\"talking to passenger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2422\n"
     ]
    }
   ],
   "source": [
    "print nb_valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set training parameters\n",
    "model_name = 'InceptionV3'\n",
    "fine_tune_layer = 133\n",
    "optimizer = 'Adam'\n",
    "learning_rate = 1e-6\n",
    "augmentation = 'yes'\n",
    "valid_set = 'p024_p026'\n",
    "batch_size = 32\n",
    "img_width, img_height = 400, 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20002 images belonging to 10 classes.\n",
      "Found 2422 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# 利用Keras的ImageDataGenerator对图片进行预处理\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        width_shift_range=0.05,\n",
    "        height_shift_range=0.05,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=10) \n",
    "#考虑到体型、姿势略有不同，设置少许的旋转、放大缩小和平移。不做翻转） \n",
    "\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "#验证集和测试集无须进行上述处理，保留原样\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  \n",
    "        target_size=(img_width,img_height),  \n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')  \n",
    "\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        valid_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(img_width,img_height),\n",
    "        shuffle=False,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "total layer count:  311 | fine tune layer:  133\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(img_width, img_height, 3))\n",
    "base_model = InceptionV3(input_tensor=inputs, weights='imagenet', include_top=False)\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "model = Model(inputs, x)\n",
    "\n",
    "print 'total layer count: ', len(base_model.layers),\n",
    "print '| fine tune layer: ', fine_tune_layer\n",
    "\n",
    "for i in range(fine_tune_layer):\n",
    "    model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "626/626 [==============================] - 789s - loss: 0.0073 - acc: 0.9982 - val_loss: 0.1821 - val_acc: 0.9348\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "result = model.fit_generator(train_generator,\n",
    "                   steps_per_epoch=nb_train_samples//batch_size+1,\n",
    "                   epochs=1,\n",
    "                   validation_data=validation_generator,\n",
    "                   validation_steps=nb_valid_samples//batch_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('models/IncpetionV3_Adam_1e-5_p024_p026-400_300_tune_133.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  | layer|  opt  |  l-rate |  aug  |    driver   |batch | epo |  t_acc  |  t_loss |  v_acc  | v_loss \n",
      "----------------------------------------------------------------------------------------------------------\n",
      "InceptionV3  |  133  |  Adam  |  1e-06  |  yes  |  p024_p026  |  32  |  0  |  0.998  |  0.007  |  0.935  |  0.182\n"
     ]
    }
   ],
   "source": [
    "#write results, use'a' to countinue writing\n",
    "import csv\n",
    "print 'model  | layer|  opt  |  l-rate |  aug  |    driver   |batch | epo |  t_acc  |  t_loss |  v_acc  | v_loss '\n",
    "print '----------------------------------------------------------------------------------------------------------'\n",
    "with open(\"result201102.csv\",\"a\") as csvfile: \n",
    "    writer = csv.writer(csvfile)\n",
    "    for i in range(len(result.epoch)):\n",
    "        writer.writerow([model_name, fine_tune_layer, optimizer, learning_rate, augmentation, \n",
    "                         valid_set, batch_size, result.epoch[i], '%.3f' % result.history['acc'][i],  \n",
    "                         '%.3f' % result.history['loss'][i], '%.3f' % result.history['val_acc'][i],\n",
    "                         '%.3f' % result.history['val_loss'][i]])\n",
    "        print model_name,' | ', fine_tune_layer,' | ', optimizer, ' | ',learning_rate,' | ', augmentation,\n",
    "        print ' | ',valid_set, ' | ', batch_size, ' | ', result.epoch[i], ' | ', \n",
    "        print '%.3f' % result.history['acc'][i],' | ','%.3f' % result.history['loss'][i], ' | ',\n",
    "        print '%.3f' % result.history['val_acc'][i],' | ','%.3f' % result.history['val_loss'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model  |  fine_tune_layer  |  optimizer  |  learning_rate  |  augmentation  |  valid_set  |  batch_size  |  epochs  |  train_acc  |  train_loss  |  valid_acc  |  valid_loss  |  train_time  | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  0  |  0.445  |  1.642  |  0.624  |  1.063  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  0  |  0.958  |  0.167  |  0.87  |  0.424  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  0  |  0.976  |  0.096  |  0.878  |  0.401  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  1  |  0.985  |  0.06  |  0.876  |  0.387  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  0  |  0.976  |  0.096  |  0.878  |  0.401  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  1  |  0.985  |  0.06  |  0.876  |  0.387  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-06  |  yes  |  p021_p022  |  64  |  0  |  0.99  |  0.036  |  0.87  |  0.37  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-06  |  yes  |  p021_p022  |  64  |  0  |  0.992  |  0.031  |  0.861  |  0.374  |    | \n",
      "ResNet50  |  109  |  Adam  |  0.0001  |  yes  |  p021_p022  |  64  |  0  |  0.973  |  0.097  |  0.906  |  0.264  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  0  |  0.995  |  0.017  |  0.922  |  0.225  |    | \n",
      "ResNet50  |  109  |  Adam  |  0.0001  |  yes  |  p021_p022  |  64  |  0  |  0.928  |  0.233  |  0.878  |  0.453  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  64  |  0  |  0.991  |  0.034  |  0.932  |  0.189  |    | \n",
      "ResNet50  |  109  |  Adam  |  0.0001  |  yes  |  p021_p022  |  32  |  0  |  0.906  |  0.293  |  0.933  |  0.269  |    | \n",
      "ResNet50  |  109  |  Adam  |  1.00E-05  |  yes  |  p021_p022  |  32  |  0  |  0.993  |  0.026  |  0.932  |  0.22  |  ResNet50  |  0  |  Adam  |  0.0001  |  yes  |  p021_p022  |  32  |  0  |  0.920  |  0.256  |  0.938  |  0.182  | \n",
      "ResNet50  |  0  |  Adam  |  1e-05  |  yes  |  p021_p022  |  32  |  0  |  0.994  |  0.025  |  0.936  |  0.218  | \n",
      "InceptionV3  |  133  |  Adam  |  0.0001  |  yes  |  p024_p026  |  32  |  0  |  0.952  |  0.166  |  0.911  |  0.244  | \n",
      "InceptionV3  |  133  |  Adam  |  1e-05  |  yes  |  p024_p026  |  32  |  0  |  0.994  |  0.022  |  0.948  |  0.151  | \n",
      "InceptionV3  |  133  |  Adam  |  1e-05  |  yes  |  p024_p026  |  32  |  0  |  0.994  |  0.022  |  0.948  |  0.151  | \n",
      "InceptionV3  |  133  |  Adam  |  1e-06  |  yes  |  p024_p026  |  32  |  0  |  0.998  |  0.007  |  0.935  |  0.182  | \n"
     ]
    }
   ],
   "source": [
    "#load csv and show results\n",
    "import csv\n",
    "with open('result201102.csv',\"r\") as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    #这里不需要readlines\n",
    "    for line in reader:\n",
    "        for i in range(len(line)):\n",
    "            print line[i],\" | \",\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2492/2492 [==============================] - 1800s  \n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_generator(test_generator,  steps=test_generator.samples//batch_size+1,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission saved\n"
     ]
    }
   ],
   "source": [
    "l = list()\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    name = fname[fname.rfind('/')+1:]\n",
    "    line = y_pred[i]\n",
    "    line = line.tolist()\n",
    "    line.insert(0,name)\n",
    "    l.append( line )\n",
    "\n",
    "l = np.array(l)\n",
    "data = {'img': l[:,0]}\n",
    "for i in range(10):\n",
    "    data[\"c%d\"%i] = l[:,i+1]\n",
    "df = pd.DataFrame(data, columns=['img'] + ['c%d'%i for i in range(10)])\n",
    "df = df.sort_values(by='img')\n",
    "df.to_csv('5_incpetionV3_p024_p026_l133.csv', index=None, float_format='%.3f')\n",
    "print(\"submission saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_submission = pd.read_csv('5_incpetionV3_p024_p026_l133.csv')\n",
    "clip_submission = pre_submission.drop('img',axis =1)\n",
    "clip_submission = clip_submission.clip(0.001,1)\n",
    "clip_submission.insert(0, 'img', pre_submission['img'])\n",
    "clip_submission.to_csv('clipped_5_incpetionV3_p024_p026_l133.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mlnd-dl]",
   "language": "python",
   "name": "conda-env-mlnd-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
